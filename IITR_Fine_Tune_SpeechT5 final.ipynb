{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IITR -Fine-Tune-SpeechT5**"
      ],
      "metadata": {
        "id": "KfTFhSTin8yI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This Project was prepared as a task given by the IIT Roorkee PARIMAL intern program. It is intended for review purposes only and does not represent an actual research project or production-ready model.*\n",
        "\n",
        "NAME : HAQ NAWAZ MALIK\n",
        "\n",
        "\n",
        "To test it on hugging face spaces live click Here below:\n",
        "\n",
        "https://huggingface.co/spaces/Omarrran/tts_model_demo"
      ],
      "metadata": {
        "id": "xCpIaMWtYK84"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVh45C0pPG3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets soundfile accelerate speechbrain==0.5.16"
      ],
      "metadata": {
        "id": "InLFsu_NGvmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "q4YEzYfYGxQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download this dataset and load it \"  https://huggingface.co/datasets/keithito/lj_speech\n",
        "\n",
        "from datasets import load_dataset, Audio\n",
        "dataset = load_dataset(\"keithito/lj_speech\", split=\"train\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "W2gnio8-LNZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "33GgyjE3HtFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "4gGgIfM9Kebq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of rows for the full dataset\n",
        "full_size = len(dataset)\n",
        "\n",
        "# Select the full dataset\n",
        "dataset = dataset.select(range(full_size))\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "UaI2t0mZKbVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LK4qrOobKlTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "id": "JKXQnTfoJNHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5Processor\n",
        "\n",
        "checkpoint = \"microsoft/speecht5_tts\"\n",
        "processor = SpeechT5Processor.from_pretrained(checkpoint)\n"
      ],
      "metadata": {
        "id": "rZaO2dNGJO6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = processor.tokenizer"
      ],
      "metadata": {
        "id": "41HXlo_WJQZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2heSA-VQ6wbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2:5]"
      ],
      "metadata": {
        "id": "AgVKf7yEJR3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's normalize the dataset, create a column called \"normalized_text\""
      ],
      "metadata": {
        "id": "H0GPu2dUHSfE"
      }
    },
    {
      "source": [
        "def extract_all_chars(batch):\n",
        "    # Assuming 'text' is the correct column name containing the transcriptions\n",
        "    all_text = \" \".join(batch[\"text\"])  # Changed \"transcription\" to \"text\"\n",
        "    vocab = list(set(all_text))\n",
        "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "\n",
        "vocabs = dataset.map(\n",
        "    extract_all_chars,\n",
        "    batched=True,\n",
        "    batch_size=-1,\n",
        "    keep_in_memory=True,\n",
        "    remove_columns=dataset.column_names,\n",
        ")\n",
        "\n",
        "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
        "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "X_2-DFZvOjl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vocab - tokenizer_vocab"
      ],
      "metadata": {
        "id": "PWPcRXZpJY-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation (except apostrophes)\n",
        "    text = re.sub(r'[^\\w\\s\\']', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Define a function to add the normalized_text column\n",
        "def add_normalized_text(example):\n",
        "    example['normalized_text'] = normalize_text(example['text'])\n",
        "    return example\n",
        "\n",
        "# Apply the function to the dataset\n",
        "dataset = dataset.map(add_normalized_text)\n",
        "\n",
        "# Print the first few examples to verify\n",
        "print(dataset[2:5])"
      ],
      "metadata": {
        "id": "tyGUOmpbLAPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_chars(batch):\n",
        "    all_text = \" \".join(batch[\"normalized_text\"])\n",
        "    vocab = list(set(all_text))\n",
        "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "\n",
        "vocabs = dataset.map(\n",
        "    extract_all_chars,\n",
        "    batched=True,\n",
        "    batch_size=-1,\n",
        "    keep_in_memory=True,\n",
        "    remove_columns=dataset.column_names,\n",
        ")\n",
        "\n",
        "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
        "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
      ],
      "metadata": {
        "id": "_AfJj2FNJtKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vocab - tokenizer_vocab"
      ],
      "metadata": {
        "id": "lJRpRh-JbjXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "speaker_model = EncoderClassifier.from_hparams(\n",
        "    source=spk_model_name,\n",
        "    run_opts={\"device\": device},\n",
        "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
        ")\n",
        "\n",
        "\n",
        "def create_speaker_embedding(waveform):\n",
        "    with torch.no_grad():\n",
        "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
        "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
        "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
        "    return speaker_embeddings"
      ],
      "metadata": {
        "id": "gZ6mMZNbdLfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(example):\n",
        "    audio = example[\"audio\"]\n",
        "\n",
        "    example = processor(\n",
        "        text=example[\"normalized_text\"],\n",
        "        audio_target=audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        return_attention_mask=False,\n",
        "    )\n",
        "\n",
        "    # strip off the batch dimension\n",
        "    example[\"labels\"] = example[\"labels\"][0]\n",
        "\n",
        "    # use SpeechBrain to obtain x-vector\n",
        "    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n",
        "\n",
        "    return example"
      ],
      "metadata": {
        "id": "OdM2RWNfg1gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_example = prepare_dataset(dataset[0])\n",
        "list(processed_example.keys())"
      ],
      "metadata": {
        "id": "JI6x3PD-g13d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_example[\"speaker_embeddings\"].shape"
      ],
      "metadata": {
        "id": "0oTcqW8sg3os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)"
      ],
      "metadata": {
        "id": "zpF2x6jlg8-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_not_too_long(input_ids):\n",
        "    input_length = len(input_ids)\n",
        "    return input_length < 300\n",
        "\n",
        "dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])\n",
        "len(dataset)"
      ],
      "metadata": {
        "id": "QnoDYrafhBeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=42)"
      ],
      "metadata": {
        "id": "ux7w-nybhNCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TTSDataCollatorWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(\n",
        "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n",
        "        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n",
        "        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n",
        "\n",
        "        # collate the inputs and targets into a batch\n",
        "        batch = processor.pad(\n",
        "            input_ids=input_ids, labels=label_features, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        batch[\"labels\"] = batch[\"labels\"].masked_fill(\n",
        "            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100\n",
        "        )\n",
        "\n",
        "        # not used during fine-tuning\n",
        "        del batch[\"decoder_attention_mask\"]\n",
        "\n",
        "        # round down target lengths to multiple of reduction factor\n",
        "        if model.config.reduction_factor > 1:\n",
        "            target_lengths = torch.tensor(\n",
        "                [len(feature[\"input_values\"]) for feature in label_features]\n",
        "            )\n",
        "            target_lengths = target_lengths.new(\n",
        "                [\n",
        "                    length - length % model.config.reduction_factor\n",
        "                    for length in target_lengths\n",
        "                ]\n",
        "            )\n",
        "            max_length = max(target_lengths)\n",
        "            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n",
        "\n",
        "        # also add in the speaker embeddings\n",
        "        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "GXRcMXXdhQ1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = TTSDataCollatorWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "_Z2Q_KrshSNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5ForTextToSpeech\n",
        "\n",
        "model = SpeechT5ForTextToSpeech.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "rXVZzQYphZim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "# disable cache during training since it's incompatible with gradient checkpointing\n",
        "model.config.use_cache = False\n",
        "\n",
        "# set language and task for generation and re-enable cache\n",
        "model.generate = partial(model.generate, use_cache=True)"
      ],
      "metadata": {
        "id": "ESMgm4K5hdDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"speecht5_finetuned_emirhan_tr\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-4,\n",
        "    warmup_steps=100,\n",
        "    max_steps=1500,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=2,\n",
        "    save_steps=100,\n",
        "    eval_steps=100,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    greater_is_better=False,\n",
        "    label_names=[\"labels\"],\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "U8BoZ8xuhe8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor,\n",
        ")"
      ],
      "metadata": {
        "id": "2-HhrQ_Gh2Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "71Le1psSjbXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "0xn3lA-Ah2nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO Test it on hugging face spaces live click Here below:\n",
        "\n",
        "https://huggingface.co/spaces/Omarrran/tts_model_demo"
      ],
      "metadata": {
        "id": "1HqzAQnYaIWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "3oVec-aUN2is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SpeechT5ForTextToSpeech.from_pretrained(\n",
        "    \"Omarrran/speecht5_finetuned_emirhan_tr\"\n",
        ")"
      ],
      "metadata": {
        "id": "DttRwG_Qh6jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "example = dataset[\"test\"][304 % len(dataset[\"test\"])] # Use modulo operator to wrap around index\n",
        "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "os7ZSCqLVK_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"As a Data Scientist, I'll be demonstrating my speaking voice in this example. If you don't like my voice, you can choose a different one by setting the speaker parameter.\""
      ],
      "metadata": {
        "id": "hu_9NGOyiCop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "number_words = {\n",
        "    0: \"zero\", 1: \"one\", 2: \"two\", 3: \"three\", 4: \"four\", 5: \"five\", 6: \"six\", 7: \"seven\", 8: \"eight\", 9: \"nine\",\n",
        "    10: \"ten\", 11: \"eleven\", 12: \"twelve\", 13: \"thirteen\", 14: \"fourteen\", 15: \"fifteen\", 16: \"sixteen\", 17: \"seventeen\",\n",
        "    18: \"eighteen\", 19: \"nineteen\", 20: \"twenty\", 30: \"thirty\", 40: \"forty\", 50: \"fifty\", 60: \"sixty\", 70: \"seventy\",\n",
        "    80: \"eighty\", 90: \"ninety\", 100: \"hundred\", 1000: \"thousand\"\n",
        "}\n",
        "\n",
        "def number_to_words(number):\n",
        "    if number < 20:\n",
        "        return number_words[number]\n",
        "    elif number < 100:\n",
        "        tens, unit = divmod(number, 10)\n",
        "        return number_words[tens * 10] + (\"-\" + number_words[unit] if unit else \"\")\n",
        "    elif number < 1000:\n",
        "        hundreds, remainder = divmod(number, 100)\n",
        "        return (number_words[hundreds] + \" hundred\" if hundreds > 1 else \"hundred\") + (\" and \" + number_to_words(remainder) if remainder else \"\")\n",
        "    elif number < 1000000:\n",
        "        thousands, remainder = divmod(number, 1000)\n",
        "        return number_to_words(thousands) + \" thousand\" + (\" \" + number_to_words(remainder) if remainder else \"\")\n",
        "    elif number < 1000000000:\n",
        "        millions, remainder = divmod(number, 1000000)\n",
        "        return number_to_words(millions) + \" million\" + (\" \" + number_to_words(remainder) if remainder else \"\")\n",
        "    elif number < 1000000000000:\n",
        "        billions, remainder = divmod(number, 1000000000)\n",
        "        return number_to_words(billions) + \" billion\" + (\" \" + number_to_words(remainder) if remainder else \"\")\n",
        "    else:\n",
        "        return str(number)\n",
        "\n",
        "def replace_numbers_with_words(text):\n",
        "    def replace(match):\n",
        "        number = int(match.group())\n",
        "        return number_to_words(number)\n",
        "\n",
        "    # Find the numbers and change with words.\n",
        "    result = re.sub(r'\\b\\d+\\b', replace, text)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "LQTOgkZ9xCIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Dictionary of technical words and their spoken equivalents (each letter separated)\n",
        "technical_words = {\n",
        "    \"API\": \"A P I\",\n",
        "    \"CUDA\": \"C U D A\",\n",
        "    \"OAuth\": \"O Auth\",\n",
        "    \"LLM\": \"L L M\",\n",
        "    \"HTTP\": \"H T T P\",\n",
        "    \"HTTPS\": \"H T T P S\",\n",
        "    \"URL\": \"U R L\",\n",
        "    \"SQL\": \"S Q L\",\n",
        "    \"JSON\": \"J S O N\",\n",
        "    \"XML\": \"X M L\",\n",
        "    \"REST\": \"R E S T\",\n",
        "    \"JWT\": \"J W T\",\n",
        "    \"FTP\": \"F T P\",\n",
        "    \"SSH\": \"S S H\",\n",
        "    \"GPU\": \"G P U\",\n",
        "    \"CPU\": \"C P U\",\n",
        "    \"IP\": \"I P\",\n",
        "    \"RAM\": \"R A M\",\n",
        "    \"ROM\": \"R O M\",\n",
        "    \"ID\": \"I D\",\n",
        "    \"UID\": \"U I D\",\n",
        "    \"UUID\": \"U U I D\",\n",
        "    \"NLP\": \"N L P\",\n",
        "    \"ML\": \"M L\",\n",
        "    \"AI\": \"A I\",\n",
        "    \"IoT\": \"I O T\",\n",
        "    \"VPN\": \"V P N\",\n",
        "    \"DNS\": \"D N S\",\n",
        "    \"SMTP\": \"S M T P\",\n",
        "    \"KNN\": \"K N N\",\n",
        "    \"CNN\": \"C N N\",\n",
        "    \"RNN\": \"R N N\",\n",
        "    \"LSTM\": \"L S T M\",\n",
        "    \"GRU\": \"G R U\",\n",
        "    # Add more technical terms with letters separated\n",
        "}\n",
        "\n",
        "def technical_words_to_speech(word):\n",
        "    # Convert technical words to their spoken form, with each letter separated by spaces\n",
        "    return technical_words.get(word, word)  # If not in the dictionary, return the original word\n",
        "\n",
        "def replace_technical_words_with_speech(text):\n",
        "    # Split the text into words and check for technical terms\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "\n",
        "    result = []\n",
        "    for word in words:\n",
        "        # Convert each word to its spoken form if it's a technical term\n",
        "        spoken_form = technical_words_to_speech(word)\n",
        "        result.append(spoken_form)\n",
        "\n",
        "    return \" \".join(result)\n",
        "\n",
        "# Example usage\n",
        "text = \"I will use an API with OAuth and CUDA to train the LLM model on a GPU.\"\n",
        "spoken_text = replace_technical_words_with_speech(text)\n",
        "print(spoken_text)\n"
      ],
      "metadata": {
        "id": "DqH-6TcRdJPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(text=final_text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "427k1nlViGDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5HifiGan\n",
        "\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
        "\n"
      ],
      "metadata": {
        "id": "or8TQBPyiLiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "import soundfile as sf\n",
        "\n",
        "Audio(speech.numpy(), rate=16000)\n",
        "# Save the audio to a file (e.g., 'output.wav')\n",
        "sf.write('output.wav', speech.numpy(), 16000)"
      ],
      "metadata": {
        "id": "S289pqndiNDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "--------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rq9mOAuR04CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO Test it on hugging face spaces live click Here below:\n",
        "\n",
        "https://huggingface.co/spaces/Omarrran/tts_model_demo"
      ],
      "metadata": {
        "id": "p-LdUX1gZZmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "thank you"
      ],
      "metadata": {
        "id": "_SO3kfKBY_r-"
      }
    }
  ]
}